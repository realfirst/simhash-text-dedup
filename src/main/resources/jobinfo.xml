<?xml version="1.0" encoding="UTF-8"?>
<content>
  <properties>
    <property>
      <name>$PWD_HOME</name>
      <value><![CDATA[/home/kaifa/xiqi]]></value>
    </property>
    <property>
      <name>$HADOOP_HOME</name>
      <value><![CDATA[/home/kaifa/Appstorage/hadoop]]></value>
    </property>
    <property>
      <name>$PARSE_HOME</name>
      <value><![CDATA[/home/kaifa/ligang]]></value>
    </property>
  </properties>
  <Jobinfo>
    <Jobs id="com.zhongsou.spider.hadoop.jobcontrol.ScoreAndClawerJob">
      <job>
        <name>score_url</name>
        <type>pipes</type>
        <shell><![CDATA[-libjars  $PWD_HOME/spider_common/target/spider_common-0.0.1-SNAPSHOT.jar -Dmapred.reduce.tasks=6 -Dmapred.job.name=score_url -Dhbase.mapreduce.inputtables=webDB,selectHostDB -Dscore_level=4 -Dread_black_list=true -files=$PWD_HOME/blackhost.txt,$PWD_HOME/blackdomain.txt,$PWD_HOME/spider_c++_common/conf/domain-suffixes.xml -Dmapred.reduce.tasks=15 -conf $PWD_HOME/spider_c++_common/conf/pipes_score_conf.xml  -inputformat com.zhongsou.spider.hbase.MultiTableInputFormat -output $score_output -writer org.apache.hadoop.mapred.SequenceFileOutputFormat  -program $score_url_bin]]></shell>
        <params>
          <param>
            <name>$score_output</name>
            <value></value>
          </param>
          <param>
            <name>$score_url_bin</name>
            <value></value>
          </param>

        </params>
      </job>

      <job>
        <name>score_new_url</name>
        <type>pipes</type>
        <shell><![CDATA[-libjars  $PWD_HOME/spider_common/target/spider_common-0.0.1-SNAPSHOT.jar -Dmapred.reduce.tasks=6 -Dmapred.job.name=score_new_url -Dhbase.mapreduce.inputtables=webDB,selectHostDB -Dscore_level=4 -Dread_black_list=true -files=$PWD_HOME/blackhost.txt,$PWD_HOME/blackdomain.txt,$PWD_HOME/spider_c++_common/conf/domain-suffixes.xml -Dmapred.reduce.tasks=15 -conf $PWD_HOME/spider_c++_common/conf/pipes_score_new_conf.xml  -inputformat com.zhongsou.spider.hbase.MultiTableInputFormat -output $score_output -writer org.apache.hadoop.mapred.SequenceFileOutputFormat  -program $score_url_bin]]></shell>
        <params>
          <param>
            <name>$score_output</name>
            <value></value>
          </param>
          <param>
            <name>$score_url_bin</name>
            <value></value>
          </param>
        </params>
      </job>

      <job>
        <name>select_url</name>
        <type>mapreduce_v2</type>
        <shell><![CDATA[com.zhongsou.spider.hbase.mapreduce.TotalValueSort -libjars  $PWD_HOME/spider_common/target/spider_common-0.0.1-SNAPSHOT.jar  -Dmapred.output.key.comparator.class=com.zhongsou.spider.hbase.mapreduce.FloatReverseComparator -Dmapreduce.outputformat.class=org.apache.hadoop.mapreduce.lib.output.SequenceFileOutputFormat -Dmapred.job.name=select_url -Dmapred.reduce.tasks=$reduce_num -DoldNewRatio=$old_new_ration $score_output $sort_select_output  $reduce_records $select_records_num ]]></shell>
        <params>
          <param>
            <name>$score_output</name>
            <value></value>
          </param>
          <param>
            <name>$sort_select_output</name>
            <value></value>
          </param>
          <param>
            <name>$reduce_records</name>
            <value></value>
          </param>
          <param>
            <name>$select_records_num</name>
            <value>5000000</value>
          </param>
          <param>
            <name>$reduce_num</name>
            <value>5</value>
          </param>
          <param>
            <name>$old_new_ration</name>
            <value>1</value>
          </param>
        </params>
      </job>


      <job>
        <name>select_new_url</name>
        <type>mapreduce_v2</type>
        <shell><![CDATA[com.zhongsou.spider.hbase.mapreduce.TotalValueSort -libjars  $PWD_HOME/spider_common/target/spider_common-0.0.1-SNAPSHOT.jar  -Dmapred.output.key.comparator.class=com.zhongsou.spider.hbase.mapreduce.FloatReverseComparator -Dmapreduce.outputformat.class=org.apache.hadoop.mapreduce.lib.output.SequenceFileOutputFormat -Dmapred.job.name=select_new_url -Dmapred.reduce.tasks=$reduce_num -DoldNewRatio=$old_new_ration $score_output $sort_select_output  $reduce_records $select_records_num ]]></shell>
        <params>
          <param>
            <name>$score_output</name>
            <value></value>
          </param>
          <param>
            <name>$sort_select_output</name>
            <value></value>
          </param>
          <param>
            <name>$reduce_records</name>
            <value></value>
          </param>
          <param>
            <name>$select_records_num</name>
            <value>10000000</value>
          </param>
          <param>
            <name>$reduce_num</name>
            <value>10</value>
          </param>
          <param>
            <name>$old_new_ration</name>
            <value>0</value>
          </param>
        </params>
      </job>

      <job>
        <name>sort_url_by_docid</name>
        <type>mapreduce_v2</type>
        <shell><![CDATA[com.zhongsou.spider.hbase.mapreduce.SortSeedURL -libjars  $PWD_HOME/spider_common/target/spider_common-0.0.1-SNAPSHOT.jar  -Dmapreduce.inputformat.class=org.apache.hadoop.mapreduce.lib.input.SequenceFileInputFormat   -Dmapred.job.name=sort_url_by_docid -Dmapred.reduce.tasks=$reduce_num  $select_output $sort_url_output ]]></shell>
        <params>
          <param>
            <name>$select_output</name>
            <value></value>
          </param>
          <param>
            <name>$sort_url_output</name>
            <value></value>
          </param>

          <param>
            <name>$reduce_num</name>
            <value>5</value>
          </param>
        </params>
      </job>


      <job>
        <name>sort_new_url_by_docid</name>
        <type>mapreduce_v2</type>
        <shell><![CDATA[com.zhongsou.spider.hbase.mapreduce.SortSeedURL -libjars  $PWD_HOME/spider_common/target/spider_common-0.0.1-SNAPSHOT.jar  -Dmapreduce.inputformat.class=org.apache.hadoop.mapreduce.lib.input.SequenceFileInputFormat   -Dmapred.job.name=sort_url_by_docid -Dmapred.reduce.tasks=$reduce_num  $select_output $sort_url_output ]]></shell>
        <params>
          <param>
            <name>$select_output</name>
            <value></value>
          </param>
          <param>
            <name>$sort_url_output</name>
            <value></value>
          </param>

          <param>
            <name>$reduce_num</name>
            <value>10</value>
          </param>
        </params>
      </job>

      <job>
        <name>claw_url</name>
        <type>pipes</type>
        <shell><![CDATA[-libjars $PWD_HOME/spider_common/target/spider_common-0.0.1-SNAPSHOT.jar -Dmapred.reduce.tasks=0  -Dmapred.map.tasks=$map_tasks_num -Dmapred.job.name=$name -Dmapred.compress.map.output=true -Dmapred.output.compress=true -Dmapred.output.compression.codec=org.apache.hadoop.io.compress.SnappyCodec -Dmapred.output.compression.type=BLOCK -Dmapred.map.output.compression.codec=org.apache.hadoop.io.compress.SnappyCodec  -conf $PWD_HOME/spider_c++_common/conf/pipes_clawer_conf.xml -files $PWD_HOME/spider_c++_common/conf/ZDP_API_webpage.ini,$PWD_HOME/spider_c++_common/conf/domain-suffixes.xml -inputformat com.zhongsou.spider.hadoop.RandomHostSequenceFileInputFormat -input $inputFile -output $output_folder -writer org.apache.hadoop.mapred.SequenceFileOutputFormat  -program $clawer_url_bin ]]></shell>
        <params>
          <param>
            <name>$map_tasks_num</name>
            <value>30</value>
          </param>

          <param>
            <name>$output_folder</name>
            <value></value>
          </param>

          <param>
            <name>$name</name>
            <value>claw_url</value>
          </param>
          <param>
            <name>$inputFile</name>
            <value></value>
          </param>
          <param>
            <name>$clawer_url_bin</name>
            <value></value>
          </param>

        </params>
      </job>





    </Jobs>
    <Jobs id="com.zhongsou.spider.hadoop.jobcontrol.ParserJob">

      <job>
        <name>parse_url</name>
        <type>pipes</type>
        <shell><![CDATA[-libjars  $PWD_HOME/spider_common/target/spider_common-0.0.1-SNAPSHOT-jar-with-dependencies.jar -Dmapred.job.name=$job_name -Dmapred.reduce.tasks=0 -Dmapred.job.queue.name=link_group -Dhadoop.pipes.java.recordreader=true -Dmapred.map.tasks=$map_num   -Dhadoop.pipes.java.recordwriter=true  -Dmapred.input.format.class=com.zhongsou.spider.hadoop.ClawerFileInputFormat -Dparser_buffer_size=$parser_buffer_size -conf $PARSE_HOME/spider_c++_common/bin/a.conf -writer org.apache.hadoop.mapred.SequenceFileOutputFormat -input $input -output $output -program $parse_content_bin]]></shell>
        <params>
          <param>
            <name>$input</name>
            <value></value>
          </param>
          <param>
            <name>$job_name</name>
            <value>parser_page</value>
          </param>
          <param>
            <name>$map_num</name>
            <value>30</value>
          </param>
          <param>
            <name>$output</name>
            <value></value>
          </param>
          <param>
            <name>$parse_content_bin</name>
            <value>bin/parse_content</value>
          </param>
          <param>
            <name>$parser_buffer_size</name>
            <value>8388608</value>
          </param>
        </params>
      </job>
      <job>
        <name>parse_convert</name>
        <type>mapreduce_v2</type>
        <shell><![CDATA[com.zhongsou.spider.hbase.mapreduce.ParseResultImporter -DseqTimestamp=$seqTimestamp -Dmapred.job.name=$job_name -libjars $PWD_HOME/spider_common/target/spider_common-0.0.1-SNAPSHOT.jar $parsed_output $parsed_convert_output ]]></shell>
        <params>
          <param>
            <name>$parsed_output</name>
            <value></value>
          </param>
          <param>
            <name>$seqTimestamp</name>
            <value></value>
          </param>
          <param>
            <name>$parsed_convert_output</name>
            <value></value>
          </param>
          <param>
            <name>$job_name</name>
            <value>parseResultConverter</value>
          </param>
        </params>
      </job>
      <job>
        <name>export_docid</name>
        <type>mapreduce_v2</type>
        <shell><![CDATA[com.zhongsou.spider.hbase.mapreduce.ExportDocid -Dmapred.reduce.tasks=$num_reduce -Dmapred.job.name=$job_name -libjars $PWD_HOME/spider_common/target/spider_common-0.0.1-SNAPSHOT.jar $clawer_docid_dir]]></shell>
        <params>
          <param>
            <name>$clawer_docid_dir</name>
            <value></value>
          </param>
          <param>
            <name>$job_name</name>
            <value>export_docid</value>
          </param>
          <param>
            <name>$num_reduce</name>
            <value>30</value>
          </param>
        </params>
      </job>

      <job>
        <name>duplicate_url</name>
        <type>mapreduce_v2</type>
        <shell><![CDATA[com.zhongsou.spider.hbase.mapreduce.DuplicateURL -Dmapred.job.name=$job_name -libjars $PWD_HOME/spider_common/target/spider_common-0.0.1-SNAPSHOT.jar $clawer_docid $parsed_url_info $duplicate_url_output $num_reduce]]></shell>
        <params>
          <param>
            <name>$clawer_docid</name>
            <value></value>
          </param>
          <param>
            <name>$job_name</name>
            <value>duplicate_url</value>
          </param>
          <param>
            <name>$parsed_url_info</name>
            <value></value>
          </param>
          <param>
            <name>$duplicate_url_output</name>
            <value></value>
          </param>
          <param>
            <name>$num_reduce</name>
            <value></value>
          </param>

        </params>
      </job>

      <job>
        <name>statistic_old_url</name>
        <type>mapreduce_v2</type>
        <shell><![CDATA[com.zhongsou.spider.hbase.mapreduce.StatisticOldURL -Dmapred.job.name=$job_name -libjars $PWD_HOME/spider_common/target/spider_common-0.0.1-SNAPSHOT.jar $parsed_urlmeta $srcdocid $oldurlimport_output]]></shell>
        <params>
          <param>
            <name>$parsed_urlmeta</name>
            <value></value>
          </param>
          <param>
            <name>$job_name</name>
            <value>statistic_old_url</value>
          </param>
          <param>
            <name>$srcdocid</name>
            <value></value>
          </param>
          <param>
            <name>$oldurlimport_output</name>
            <value></value>
          </param>

        </params>
      </job>

      <job>
        <name>statistic_new_url</name>
        <type>mapreduce_v2</type>
        <shell><![CDATA[com.zhongsou.spider.hbase.mapreduce.StatisticNewURL -Dmapred.job.name=$job_name -libjars $PWD_HOME/spider_common/target/spider_common-0.0.1-SNAPSHOT.jar $new_url_info  $newurlimport_output]]></shell>
        <params>
          <param>
            <name>$new_url_info</name>
            <value></value>
          </param>
          <param>
            <name>$job_name</name>
            <value>statistic_new_url</value>
          </param>
          <param>
            <name>$newurlimport_output</name>
            <value></value>
          </param>

        </params>
      </job>
    </Jobs>
    
    <Jobs id="com.zhongsou.spider.hadoop.jobcontrol.SelectAndSendJob">
      <job>
        <name>generate_dup_pair</name>
        <type>mapreduce_v2</type>
        <shell><![CDATA[com.zhongsou.incload.DeDup -DseqTimestamp=$seqTimestamp -Durlid_finger_load_file=$urlid_finger_file  -Dmapred.reduce.tasks=$num_reduce -Dmapred.job.name=$job_name -libjars $PWD_HOME/spider_common/target/spider_common-0.0.1-SNAPSHOT.jar $pair_output]]></shell>
        <params>
          <param>
            <name>$seqTimestamp</name>
            <value></value>
          </param>
          <param>
            <name>$urlid_finger_file</name>
            <value></value>
          </param>
          <param>
            <name>$num_reduce</name>
            <value>10</value>
          </param>
          <param>
            <name>$job_name</name>
            <value>generate_dup_pair</value>
          </param>
          <param>
            <name>$pair_output</name>
            <value></value>
          </param>

        </params>
      </job>

      <job>
        <name>select_dup_pair</name>
        <type>mapreduce_v2</type>
        <shell><![CDATA[com.zhongsou.incload.SelectLogic -DseqTimestamp=$seqTimestamp  -Dmapred.job.name=$job_name -libjars $PWD_HOME/spider_common/target/spider_common-0.0.1-SNAPSHOT.jar $select_input_dir $select_output_dir ]]></shell>
        <params>
          <param>
            <name>$seqTimestamp</name>
            <value></value>
          </param>

          <param>
            <name>$job_name</name>
            <value>select_dup_pair</value>
          </param>
          <param>
            <name>$select_input_dir</name>
            <value></value>
          </param>
          <param>
            <name>$select_output_dir</name>
            <value></value>
          </param>


        </params>
      </job>

      <job>
        <name>generate_load_flag_hfile</name>
        <type>mapreduce_v2</type>
        <shell><![CDATA[com.zhongsou.spider.hbase.mapreduce.HBLoadFlagUpdater -DserialNumber=$serialNumber -DseqTimestamp=$seqTimestamp  -Dmapred.job.name=$job_name -libjars $PWD_HOME/spider_common/target/spider_common-0.0.1-SNAPSHOT.jar   $modify_list $load_list $finger_list $hfile_output ]]></shell>
        <params>
          <param>
            <name>$seqTimestamp</name>
            <value></value>
          </param>

          <param>
            <name>$job_name</name>
            <value>generate_load_flag_hfile</value>
          </param>
          <param>
            <name>$modify_list</name>
            <value></value>
          </param>
          <param>
            <name>$serialNumber</name>
            <value></value>
          </param>

          <param>
            <name>$load_list</name>
            <value></value>
          </param>
          <param>
            <name>$finger_list</name>
            <value></value>
          </param>

          <param>
            <name>$hfile_output</name>
            <value></value>
          </param>

        </params>
      </job>

      <job>
        <name>generate_send_file</name>
        <type>mapreduce_v2</type>
        <shell><![CDATA[com.zhongsou.spider.hbase.mapreduce.SendWebPage -DserialNumber=$serialNumber -DseqTimestamp=$seqTimestamp  -Dmapred.job.name=$job_name -libjars $PWD_HOME/spider_common/target/spider_common-0.0.1-SNAPSHOT.jar  $load_file $delete_file $send_output]]></shell>
        <params>
          <param>
            <name>$seqTimestamp</name>
            <value></value>
          </param>

          <param>
            <name>$job_name</name>
            <value>generate_send_file</value>
          </param>
          <param>
            <name>$load_file</name>
            <value></value>
          </param>
          <param>
            <name>$serialNumber</name>
            <value></value>
          </param>

          <param>
            <name>$delete_file</name>
            <value></value>
          </param>
          <param>
            <name>$send_output</name>
            <value></value>
          </param>

        </params>
      </job>
    </Jobs>
    
  </Jobinfo>

</content>
